
1. 字典如何进行快速排序：
   a = {"cats":1,"dogs":0}
   如果想要获得b = ["dogs","cats"]，即根据标签的大小顺序获得key的列表，方法如下：
   b=[m[0] for m in sorted(a.items(),key=lambda x:x[1])]
   这里面的key选择的是x的第二项作为参考
   
2.ImageDataGenerator在flow或者flow_from_directory之后，可以调用class_indices来查看对应的文件名和标签的字典：
  例如：
  a = ImageGenerator()
  b = a.flow_from_directory()
  b.class_indices 不带括号，获取的是一个字典{“cats":1,"dogs":0}
  b.samples返回有多少个样本
  在循环里面用：
  for i in range(b.samples):
      x,y=b.next()
   这样可以每次返回一个生成器增强后的图片以及标签
   
3. keras的model函数，model.summary()函数，可以打印出模型信息
   model.get_weights()返回模型权重列表，类型是ndarray

4. 神经网络中BN的用法，一般用在conv或者dense之前，主要作用是加快训练速度，不用也可以

5. keras.layers.concatenate()函数，主要用于共享层模型，例如：
   a. 同一个输入，经过不同的网络提取特征，dense1,dense2,dense3,然后进行拼接dense = concatenate([dense1,dense2,dense3]),
      最后再加上top层，例如全链接，这样的好处是增加了特征的可解释性。
   b. 多个输入的情况，经过相同或者不同的网络提取特征知乎，进行拼接，然后再连接top层，例如：当输入的是两张图像或者是两种不同类型的数据的时候。
   另外没有用到concatenate()函数，但是也是共享层模型的例子：同一个输入多个输出的模型，用来做两个类型的分类等。
   
   如果拼接的两个层都是已经打平了的，即是一维的，则直接在长度上拼接，例如512+256拼接之后变成一条长度为768的特征

如果拼接两个卷积层，例如经过原图大小64*64*3，输入时一个batch_size为32，经过一个3*3通道为512的conv1提取的特征是e是64*64*512，经过一个5*5通道
   为256的conv2提取的特征为f是64*64*256，注意是在通道的那个维度上进行拼接，即axis=-1,最后的shape为32（batch)*64*64(高宽）*768(通道数，
   也是特征图的个数)
   
6. numpy array格式的数据如何保存成图片：
   a. 方法1 from PIL import Image
      img=Image.fromarray(array)
      img.save("a.jpg")
   b. import scipy.misc
      scipy.misc.imsave("a.jpg",array)
   c. import matplotlib
      matplotlib.image.imsave("a.jpg",array)
 
 7. python有这种比较简单的句法：
      return 10 if x>10 else -10
  
 8. enumerate()函数：
      a=[1,2,3] b=[4,5,6,7]
      for inx,val in enumerate([a,b]):
         print(inx,val)
      这里是会针对a,b构成的这个列表进行访问，依次返回的是0,[1,2,3]和1,[4,5,6]
   
 9. 眼科多分类的工程：multi_multi_task_eyes.py文件，这个是六个分类一起做的包括白内障，角膜炎，视网膜，青光眼，正常前眼，正常后眼这六个类
    代码梳理：
    a. 关于data和model，都分别封装了类，这样函数逻辑要清晰一些；
    b. 在利用ImageDataGenerator()函数的时候，除了常用的旋转，缩放，scale，镜像等，
    还加了一个keras.applications.utils import preprocess_input这个函数，传参是：
      ImageDataGenerator(preprocessing_function=self.image_pre)
      其中：
      self.image_pre(img):
         a = np.expand_dims(img)
         a = preprocess_input(a)
         return a[0]
    c. 尝试使用的basenet有inceptionv3,vgg19,densenet169,resnet50这四种，且设置trianable = false的时候，传得是一个比例，即basenet的前80%
       的权重不需要再训练
    d. 做multi_task的方式有两种，一种是6个dense(1)做拼接之后作为整个模型的output，另外一种方法是6个dense(256)之后拼接，拼接完之后再加上
       top层dense(6)作为输出。
    e. 可以多次调用训练的函数，不过每次传入的学习率，epochs这些不一样，用于做不同的尝试。
    
10.  np.ramdom.randn(3,4,4)会随机生成维度为（3，4，4）的随机数，取值范围在0到1之间。

11.  回归问题和分类问题：
     分类问题是最后输出的是一个定性的值，是哪个类别
     回归问题最后输出的是一个定量的值，是具体的连续的数值，例如股价，天气温度等等。
     物体检测就是一个分类加回归的问题，判断是哪一个类属于分类问题，返回具体的位置坐标，就是一个回归问题。

12.  resnet残差网络，x---卷积层-----y，改进的地方在于增加了一条线，x直接到y，对于这样做的好处最通俗的理解是：如果我在增加的这一层卷积网络效果不好是个累赘，nad
     那大不了这一层卷积层的参数全部更新为0，这样只保留等值传递的那条线，这样，最差的结果也只是这一层没有起到作用，但是大多数情况还是能祈祷作用的，这
     是一种比较保守的做法。
 
13. 如何使用gitlab:
   配置SSH网页上都有，本地建立一个文件夹就行，然后进入这个文件夹，右键git bash here，进入控制台页面
   首先是到网页整个工程，是大的工程而不是分支，先拉到自己的本地，用的是 git clone https://gitlab.genomics.cn/BIGDATA-APP/dc_dc.git
   注意后面是工程的网址，加上.git后缀；
   如果要拉哪一个分支，就接着使用命令： git checkout adjust_ranking,这样本地的文件夹下面就是adjust_ranking分支下面所有的文件；
   本地的文件改了之后，先要push到本地缓存，先用命令 git add search/ 相当于把里卖弄的search文件夹先推到缓存区，如果用git add .就是当前文件夹下的全都推上去；
   然后再调用命令：git commit -m "lss shhdaf",这里是做一些修改的备注说明;
   最后调用命令：git push origin adjust_ranking就把文件传到远程的adjust_ranking分支上去了。
   
14. resnet，常用的结构就是resnet50,结构如下：
   7*7*64conv---pool---（1*1*64conv，3*3*64conv,1*1*256conv）*3+(128)*3+(256)*3+(512)*3+average_pool+dense

15. 卷积神经网络中strides,padding的含义，strides才是对应的卷积模板移动的步长，例如移动步长为2，padding=same的话，最终图片大小缩小为原来的0.5倍

16. Inception,google_net:
    inception网络有三个版本
    google_net，中间加了两个softmax输出？
   
17. pycharm激活方式比较好的网址
https://blog.csdn.net/yanjiangdi/article/details/80508981
